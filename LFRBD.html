<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>LFRBD</title>
    <link rel="stylesheet" type="text/css" href="assets/scripts/bulma.min.css">
    <link rel="stylesheet" type="text/css" href="assets/scripts/theme.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>
  <body>
    <section class="hero is-light" style="">
      <div class="hero-body" style="padding-top: 50px;">
        <div class="container" style="text-align: center;margin-bottom:5px;">
          <h1 class="title">
            Efficient Low-Resolution Face Recognition via
          </h1>
          <h1 class="title">
            Bridge Distillation
          </h1>

          <div class="author">Shiming Ge</div>
          <div class="author">Shengwei Zhao</div>
          <div class="author">Chenyu Li</div>
          <div class="author">Yu Zhang</div>
          <div class="author">Jia Li</div>
          <div class="group">
            <a href="http://cvteam.net/">CVTEAM</a>
          </div>
          <div class="aff">
            <p><sup>1</sup>State Key Laboratory of Virtual Reality Technology and Systems, SCSE, Beihang University, Beijing, China</p>
          </div>
          <div class="con">
            <p  style="font-size: 24px; margin-top:5px; margin-bottom: 15px;">
            TIP 2020
            </p>
          </div>
          <div class="columns">
            <div class="column"></div>
            <div class="column"></div>
            <div class="column">
              <a href="http://cvteam.net/papers/2020-TIP-Efficient%20Low-Resolution%20Face%20Recognition%20via%20Bridge%20Distillation.pdf" target="_blank">
                <p class="link">Paper</p>
              </a>
            </div>
            <div class="column">
              <a href="https://github.com/iCVTEAM/LFRBD/" target="_blank">
                <p class="link">Code</p>
              </a>
            </div>
            <div class="column"></div>
            <div class="column"></div>
          </div>
        </div>
      </div>
    </section>
    <div style="text-align: center;">
      <div class="container" style="max-width:850px">
        <div style="text-align: center;">
          <img src="assets/LFRBD/head.png" class="centerImage">
        </div>
      </div>
      <div class="head_cap">
        <p style="color:gray;">
           The bridge distillation framework
        </p>
      </div>
    </div>
    <section class="hero">
      <div class="hero-body">
        <div class="container" style="max-width: 800px" >
          <h1 style="">Abstract</h1>
          <p  style="text-align: justify; font-size: 17px;">
            Face recognition in the wild is now advancing 
            towards light-weight models, fast inference speed and 
            resolution-adapted capability. In this paper, we propose a bridge distillation 
            approach to turn a complex face model pretrained on private 
            high-resolution faces into a light-weight one for low-resolution 
            face recognition. In our approach, such a cross-dataset 
            resolution-adapted knowledge transfer problem is solved via two-step 
            distillation. In the first step, we conduct cross-dataset distillation 
            to transfer the prior knowledge from private high-resolution 
            faces to public high-resolution faces and generate compact and 
            discriminative features. In the second step, the resolution-adapted 
            distillation is conducted to further transfer the prior knowledge 
            to synthetic low-resolution faces via multi-task learning. By 
            learning low-resolution face representations and mimicking the 
            adapted high-resolution knowledge, a light-weight student model 
            can be constructed with high efficiency and promising accuracy 
            in recognizing low-resolution faces. Experimental results show 
            that the student model performs impressively in recognizing 
            low-resolution faces with only 0.21M parameters and 0.057MB 
            memory. Meanwhile, its speed reaches up to 14,705, 934 and 763 
            faces per second on GPU, CPU and mobile phone, respectively. 
          </p>
        </div>
      </div>
    </section>
    <section class="hero is-light" style="background-color:#FFFFFF;">
      <div class="hero-body">
        <div class="container" style="max-width:800px;margin-bottom:20px;">
          <h1>
            Resource Costs Comparison
          </h1>
        </div>
        <div class="container" style="max-width:800px">
          <div style="text-align: center;">
            <img src="assets/LFRBD/result.png" class="centerImage">
          </div>
        </div>
      </div>
    </section>
  <section class="hero" style="padding-top:0px;">
    <div class="hero-body">
      <div class="container" style="max-width:800px;">
  <div class="card">
  <header class="card-header">
    <p class="card-header-title">
      BibTex Citation
    </p>

    <a class="card-header-icon button-clipboard" style="border:0px; background: inherit;" data-clipboard-target="#bibtex-info" >
      <i class="fa fa-copy" height="20px"></i>
    </a>
  </header>
    <div class="card-content">
<pre style="background-color:inherit;padding: 0px;" id="bibtex-info">@article{ge2020efficient,
  title={Efficient Low-Resolution Face Recognition via Bridge Distillation},
  author={Ge, Shiming and Zhao, Shengwei and Li, Chenyu and Zhang, Yu and Li, Jia},
  journal={IEEE Transactions on Image Processing},
  year={2020},
  publisher={IEEE}
}</pre>
    </div>
    </section>
    <script type="text/javascript" src="assets/scripts/clipboard.min.js"></script>
    <script>
      new ClipboardJS('.button-clipboard');
    </script>
  </body>
</html>
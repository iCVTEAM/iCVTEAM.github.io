<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>E<sup>2</sup>NeRF</title>
    <link rel="stylesheet" type="text/css" href="assets/scripts/bulma.min.css">
    <link rel="stylesheet" type="text/css" href="assets/scripts/theme.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>
  <body>
    <section class="hero is-light" style="">
      <div class="hero-body" style="padding-top: 50px;">
        <div class="container" style="text-align: center;margin-bottom:5px;">
          <h1 class="title">
            E<sup>2</sup>NeRF: Event Enhanced Neural Radiance Fields from Blurry Images
          </h1>
          <div class="author"><p  style="font-size: 22px">Yunshan Qi<sup>1</sup> &nbsp&nbsp&nbsp&nbsp&nbsp Lin Zhu<sup>2 *</sup> &nbsp&nbsp&nbsp&nbsp&nbsp Yu Zhang<sup>3</sup> &nbsp&nbsp&nbsp&nbsp&nbsp Jia Li<sup>1,4 *</sup></p></div>
          <div class="aff">
            <p style="font-size: 20px"><sup>1</sup>Beihang University &nbsp&nbsp&nbsp <sup>2</sup>Beijing Institute of Technology &nbsp&nbsp&nbsp <sup>3</sup>SenseTime and Tetras.AI &nbsp&nbsp&nbsp  <sup>4</sup>Peng Cheng Laboratory</p>
            <p> </p>
          </div>
          <div class="group"><p  style="font-size: 22px"><a href="http://cvteam.net/">CVTEAM</a></p></div>
          <div class="con">
            <p  style="font-size: 24px; margin-top:5px; margin-bottom: 15px;">
            <b>Accepted by International Conference on Computer Vision (ICCV) 2023</b>
            </p>
          </div>
          <div class="columns">
            <div class="column"></div>
            <div class="column"></div>
            <div class="column">
              <a href="assets/E2NeRF/Papers.pdf" target="_blank">
                <p class="link"  style="font-size: 24px; margin-top:5px; margin-bottom: 15px;">[Paper]</p>
              </a>
            </div>
            <div class="column">
              <a href="https://github.com/iCVTEAM/E2NeRF" target="_blank">
                <p class="link"  style="font-size: 24px; margin-top:5px; margin-bottom: 15px;">[Code]</p>
              </a>
            </div>
            <div class="column"></div>
            <div class="column"></div>
          </div>
        </div>
      </div>
    </section>


    <div style="text-align: center;">
      <div class="head_cap">
        <p style="font-size: 20px">
          <b>The Framework of E<sup>2</sup>NeRF</b>
        </p>
      </div>
      <div class="container" style="max-width:850px">
        <div style="text-align: center;">
          <img src="./assets/E2NeRF/method.png" class="centerImage">
        </div>
      </div>

    </div>

    <div style="text-align: center;">
      <div class="head_cap">
        <p style="font-size: 20px">
          <b>The Results of E<sup>2</sup>NeRF</b>
        </p>
      </div>
      <div class="container" style="max-width:850px">
        <div style="text-align: center;">
          <img src="./assets/E2NeRF/gif4.gif" class="centerImage">
        </div>
      </div>
    </div>


    <section class="hero">
      <div class="hero-body">
        <div class="container" style="max-width: 800px" >
          <h1 style="">Abstract</h1>
          <p  style="text-align: justify; font-size: 16px;">
            Neural Radiance Fields (NeRF) achieves impressive rendering performance by learning volumetric 3D representation from several images of different views.
            However, it is difficult to reconstruct a sharp NeRF from blurry input as often occurred in the wild.
            To solve this problem, we propose a novel Event-Enhanced NeRF (E<sup>2</sup>NeRF) by utilizing the combination data of a bio-inspired event camera and a standard RGB camera.
            To effectively introduce event stream into the learning process of neural volumetric representation, we propose a blur rendering loss and an event rendering loss, which guide the network via modelling real blur process and event generation process, respectively.
            Moreover, a camera pose estimation framework for real-world data is built with the guidance of event stream to generalize the method to practical applications.
            In contrast to previous image-based or event-based NeRF, our framework effectively utilizes the internal relationship between events and images.
            As a result, E<sup>2</sup>NeRF not only achieves image deblurring but also achieves high-quality novel view image generation.
            Extensive experiments on both synthetic data and real-world data demonstrate that E<sup>2</sup>NeRF can effectively learn a sharp NeRF from blurry images, especially in complex and low-light scenes.
          </p>
        </div>
      </div>
    </section>



    <section class="hero">
      <div class="hero-body">
        <div class="container" style="max-width: 800px" >
          <h1 style="">Supplementary Video</h1>
          <iframe width="800" height="450" src="https://www.youtube.com/embed/EvTHcLFX8yY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
      </div>
    </section>


    <section class="hero is-light" style="background-color:#FFFFFF;">
      <div class="hero-body">
        <div class="container" style="max-width:800px;margin-bottom:20px;">
          <h1>
            Qualitative Comparison on Synthetic Data
          </h1>
        </div>
        <div class="container" style="max-width:800px">
          <div style="text-align: center;">
            <img src="./assets/E2NeRF/qualitative1.png" class="centerImage">
          </div>
        </div>
        <div class="container" style="max-width:800px;margin-bottom:20px;">
          <h1>
            Qualitative Comparison on Real Data
          </h1>
        </div>
        <div class="container" style="max-width:800px">
          <div style="text-align: center;">
            <img src="./assets/E2NeRF/qualitative2.png" class="centerImage">
          </div>
        </div>
      </div>
    </section>

  <section class="hero" style="padding-top:0px;">
    <div class="hero-body">
      <div class="container" style="max-width:800px;">
  <div class="card">
  <!--header class="card-header">
    <p class="card-header-title">
      BibTex Citation
    </p>

    <a class="card-header-icon button-clipboard" style="border:0px; background: inherit;" data-clipboard-target="#bibtex-info" >
      <i class="fa fa-copy" height="20px"></i>
    </a>
  </header>
    <div class="card-content">
<pre style="background-color:inherit;padding: 0px;" id="bibtex-info">@article{Ma_Xia_Li_2021,
  title={Pyramidal Feature Shrinking for Salient Object Detection},
  volume={35},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/16331},
  number={3},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  author={Ma, Mingcan and Xia, Changqun and Li, Jia},
  year={2021},
  month={May},
  pages={2311-2318}
}</pre-->
    </div>
    </section>
    <script type="text/javascript" src="assets/scripts/clipboard.min.js"></script>
    <script>
      new ClipboardJS('.button-clipboard');
    </script>
  </body>
</html>
